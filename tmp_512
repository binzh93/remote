# -*- coding: utf8 -*-
import tensorflow as tf
import numpy as np
import time


class improcess():
    def __init__(self):
        self.file1 = '/home/zb/zzz/tuu/2015_all_fang.tif'
        self.file2 = '/home/zb/tmp/sp_new/sp_tiff/'
        self.file3 = '/home/zb/tmp/1/quickbird2015.tif'
        self.file4 = '/home/zb/tmp/sp_new/labeltiff/'

    def read_bacth_multifile(self, filein_path, bacth_size):
        reader = tf.TFRecordReader()
        files = tf.train.match_filenames_once(filein_path)

        filename_queue = tf.train.string_input_producer(files)
        _, queue_batch = reader.read_up_to(filename_queue, bacth_size)
        features = tf.parse_example(queue_batch, features={
            'image_raw': tf.FixedLenFeature([], tf.string),
        })

        imgs = tf.decode_raw(features['image_raw'], tf.float32)

        images_bacth = tf.reshape(imgs, (bacth_size, 224, 224, 8))

        return files, images_bacth

    def read_batch(self, filename, batch_size):
        # filename= '/home/zb/split_hhh/train15.tfrecords'
        file_queue = tf.train.string_input_producer([filename])
        reader = tf.TFRecordReader()
        _, queue_batch = reader.read_up_to(file_queue, batch_size)
        feature = tf.parse_example(queue_batch, features={
            'img_raw': tf.FixedLenFeature([], tf.string),
            'labels': tf.FixedLenFeature([], tf.string)
        })
        imgs = tf.decode_raw(feature['img_raw'], tf.float32)
        labels = tf.decode_raw(feature['labels'], tf.int32)

        img_batch = tf.reshape(imgs, (batch_size, 512, 512, 4))
        label_batch = tf.reshape(labels, (batch_size, 512, 512))

        return img_batch, label_batch

    def read_batch_nolabel(self, filename, batch_size):
        # filename= '/home/zb/split_hhh/train15.tfrecords'
        file_queue = tf.train.string_input_producer([filename])
        reader = tf.TFRecordReader()
        _, queue_batch = reader.read_up_to(file_queue, batch_size)
        feature = tf.parse_example(queue_batch, features={
            'img_raw': tf.FixedLenFeature([], tf.string),
        })
        imgs = tf.decode_raw(feature['img_raw'], tf.float32)

        img_batch = tf.reshape(imgs, (batch_size, 512, 512, 4))

        return img_batch


class SegNet():
    def __init__(self, num_epochs, batch_size, learning_rate, learning_rate_decay, moving_average_decay):
        self.num_epochs = num_epochs
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.learning_rate_decay = learning_rate_decay
        self.moving_average_decay = moving_average_decay

    # batch normalization
    def batch_normalization(self, input, isTraining, name):
        return tf.cond(isTraining,
                       lambda: tf.contrib.layers.batch_norm(input, is_training=isTraining, scope=name + '_bn'),
                       lambda: tf.contrib.layers.batch_norm(input, is_training=isTraining, scope=name + '_bn',
                                                            reuse=True))  # reuse=True

    def conv_op(self, input, kernel_shape, stride, name=None):
        depth = kernel_shape[3]
        with tf.variable_scope('conv' + name) as scope:
            '''
            kernel = tf.get_variable('conv-kernel', shape=kernel_shape,
                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())  # attention
            '''
            kernel = tf.get_variable('conv-kernel', shape=kernel_shape,
                                     initializer=tf.truncated_normal_initializer(stddev=0.1))  # attention


            biases = tf.get_variable('conv-biases', shape=[depth],
                                     initializer=tf.constant_initializer(0.0))
            conv = tf.nn.conv2d(input, kernel, strides=[1, stride, stride, 1], padding='SAME', name=scope.name)
            layer = tf.nn.bias_add(conv, biases)
            relu_val = tf.nn.relu(layer)

        return relu_val

    def deconv_op(self, input, kernel_shape, out_shape, stride, name=None):
        # attention kernel_shape's [2] [3] is changed, cause it's deconvolution
        depth = kernel_shape[2]
        with tf.variable_scope('deconv' + name) as scope:
            '''
            kernel = tf.get_variable('deconv-kernel', shape=kernel_shape,
                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())  # attention
            '''
            kernel = tf.get_variable('deconv-kernel', shape=kernel_shape,
                                     initializer=tf.truncated_normal_initializer(stddev=0.1))  # attention


            biases = tf.get_variable('deconv-biases', shape=[depth],
                                     initializer=tf.constant_initializer(0.0))

            deconv = tf.nn.conv2d_transpose(input, kernel, out_shape, strides=[1, stride, stride, 1],
                                            padding='SAME',
                                            name=scope.name)
            layer = tf.nn.bias_add(deconv, biases)
            relu_val = tf.nn.relu(layer)


        return relu_val

    def max_pool_with_argmax_op(self, input, stride, name):
        # tf.nn.max_pool_with_argmax, only GPU-supported, tf.nn.max_pool_with_argmax_and_mask seem to high version support
        return tf.nn.max_pool_with_argmax(input, ksize=[1, 2, 2, 1], strides=[1, stride, stride, 1], padding='SAME', name=name)

    def unpool(self, net, mask, stride, name):
        assert mask is not None
        with tf.name_scope(name):
            ksize = [1, stride, stride, 1]
            input_shape = net.get_shape().as_list()
            #  calculation new shape
            output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])
            # calculation indices for batch, height, width and feature maps
            one_like_mask = tf.ones_like(mask)
            batch_range = tf.reshape(tf.range(output_shape[0], dtype=tf.int64), shape=[input_shape[0], 1, 1, 1])
            b = one_like_mask * batch_range
            y = mask // (output_shape[2] * output_shape[3])
            x = mask % (output_shape[2] * output_shape[3]) // output_shape[3]
            feature_range = tf.range(output_shape[3], dtype=tf.int64)
            f = one_like_mask * feature_range
            # transpose indices & reshape update values to one dimension
            updates_size = tf.size(net)
            indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [4, updates_size]))
            values = tf.reshape(net, [updates_size])
            ret = tf.scatter_nd(indices, values, output_shape)
            return ret

    def is_keep_pro(self, in_tensor, isTraining, name=None):
        return tf.cond(isTraining,
                       lambda: tf.layers.dropout(inputs=in_tensor, rate=0.5, name='drop' + name),
                       lambda: tf.layers.dropout(inputs=in_tensor, rate=0.0, name='drop' + name))



    def inference(self, images, isTraining):

        img_lrn = tf.nn.lrn(images, depth_radius=5, bias=1.0, alpha=0.0001, beta=0.75, name='img_lrn')
        # encode  images (batch_size, height, width, channels)
        conv1_1 = self.conv_op(images, [3, 3, img_lrn.get_shape().as_list()[3], 64], stride=1, name='1_1')  # (?, 512, 512, 4) ->  (?, 512, 512, 64)
        conv1_2 = self.conv_op(conv1_1, [3, 3, 64, 64], stride=1, name='1_2')  # (?, 512, 512, 64) ->  (?, 512, 512, 64)
        pool1, arg1 = self.max_pool_with_argmax_op(conv1_2, stride=2, name='pool1')  # (?, 512, 512, 64) ->  (?, 256, 256, 64)

        conv2_1 = self.conv_op(pool1, [3, 3, 64, 128], stride=1,  name='2_1')  # (?, 256, 256, 64) ->  (?, 256, 256, 128)
        conv2_2 = self.conv_op(conv2_1, [3, 3, 128, 128], stride=1, name='2_2')  # (?, 256, 256, 128) ->  (?, 256, 256, 128)
        pool2, arg2 = self.max_pool_with_argmax_op(conv2_2, stride=2, name='pool2')  # (?, 256, 256, 128) ->  (?, 128, 128, 128)

        conv3_1 = self.conv_op(pool2, [3, 3, 128, 256], stride=1, name='3_1')  # (?, 128, 128, 128) ->  (?, 128, 128, 256)
        conv3_2 = self.conv_op(conv3_1, [3, 3, 256, 256], stride=1, name='3_2')  # (?, 128, 128, 256) ->  (?, 128, 128, 256)
        pool3, arg3 = self.max_pool_with_argmax_op(conv3_2, stride=2, name='pool3')  # (?, 128, 128, 256) ->  (?, 64, 64, 256)
        drop3 = self.is_keep_pro(pool3, isTraining, '3')

        conv4_1 = self.conv_op(drop3, [3, 3, 256, 512], stride=1, name='4_1')  # (?, 64, 64, 256) ->  (?, 64, 64, 512)
        conv4_2 = self.conv_op(conv4_1, [3, 3, 512, 512], stride=1, name='4_2')  # (?, 64, 64, 512) ->  (?, 64, 64, 512)
        #drop4 = self.is_keep_pro(conv4_2, isTraining, '4')               # (?, 64, 64, 512) ->  (?, 64, 64, 512)
        pool4, arg4 = self.max_pool_with_argmax_op(conv4_2, stride=2, name='pool4')  # (?, 64, 64, 512) ->  (?, 32, 32, 512)
        drop4 = self.is_keep_pro(pool4, isTraining, '4')


        conv5_1 = self.conv_op(drop4, [3, 3, 512, 1024], stride=1, name='5_1')  # (?, 32, 32, 1024) ->  (?, 32, 32, 1024)
        conv5_2 = self.conv_op(conv5_1, [3, 3, 1024, 1024], stride=1, name='5_2')  # (?, 32, 32, 1024) ->  (?, 32, 32, 1024)
        pool5, arg5 = self.max_pool_with_argmax_op(conv5_2, stride=2, name='pool5')  # (?, 16, 16, 1024) ->  (?, 16, 16, 1024)
        drop5 = self.is_keep_pro(pool5, isTraining, '5')   # (?, 16, 16, 1024)

        # decode
        unsampling6 = self.unpool(drop5, arg5, stride=2, name='unsampling6')    # (?, 32, 32, 1024)
        deconv6_1 = self.deconv_op(unsampling6, [3, 3, 512, 1024], [self.batch_size, 32, 32, 512], stride=1, name='6_1')    # (?, 32, 32, 1024) -> (?, 32, 32, 512)
        merge6 = tf.concat((deconv6_1, drop4), axis=3)
        conv6_2 = self.conv_op(merge6, [3, 3, 1024, 512], stride=1, name='6_2')
        conv6_3 = self.conv_op(conv6_2, [3, 3, 512, 512], stride=1, name='6_3')    # (?, 32, 32, 512)

        unsampling7 = self.unpool(conv6_3, arg4, stride=2, name='unsampling7')  # (?, 64, 64, 512)
        deconv7_1 = self.deconv_op(unsampling7, [3, 3, 256, 512], [self.batch_size, 64, 64, 256], stride=1, name='7_1')  # (?, 64, 64, 512) -> (?, 64, 64, 256)
        merge7 = tf.concat((deconv7_1, drop3), axis=3)
        conv7_2 = self.conv_op(merge7, [3, 3, 512, 256], stride=1, name='7_2')
        conv7_3 = self.conv_op(conv7_2, [3, 3, 256, 256], stride=1, name='7_3')  # (?, 64, 64, 256)

        unsampling8 = self.unpool(conv7_3, arg3, stride=2, name='unsampling8')  # (?, 128, 128, 256)
        deconv8_1 = self.deconv_op(unsampling8, [3, 3, 128, 256], [self.batch_size, 128, 128, 128], stride=1, name='8_1')  # (?, 128, 128, 256) -> (?, 128, 128, 128)
        merge8 = tf.concat((deconv8_1, pool2), axis=3)
        conv8_2 = self.conv_op(merge8, [3, 3, 256, 128], stride=1, name='8_2')
        conv8_3 = self.conv_op(conv8_2, [3, 3, 128, 128], stride=1, name='8_3')  # (?, 128, 128, 128)

        unsampling9 = self.unpool(conv8_3, arg2, stride=2, name='unsampling9')  # (?, 256, 256, 128)
        deconv9_1 = self.deconv_op(unsampling9, [3, 3, 64, 128], [self.batch_size, 256, 256, 64], stride=1, name='9_1')  # (?, 256, 256, 128) -> (?, 256, 256, 64)
        merge9 = tf.concat((deconv9_1, pool1), axis=3)
        conv9_2 = self.conv_op(merge9, [3, 3, 128, 64], stride=1, name='9_2')
        conv9_3 = self.conv_op(conv9_2, [3, 3, 64, 64], stride=1, name='9_3')  # (?, 256, 256, 64)

        unsampling10 = self.unpool(conv9_3, arg1, stride=2, name='unsampling10')  # (?, 512, 512, 64)
        deconv10_1 = self.deconv_op(unsampling10, [3, 3, 64, 64], [self.batch_size, 512, 512, 64], stride=1, name='10_1')  # (?, 512, 512, 64) -> (?, 512, 512, 64)
        #merge10 = tf.concat((deconv10_1, conv1_2), axis=3)
        #conv10_2 = self.conv_op(merge10, [3, 3, 128, 64], stride=1, name='10_2')
        conv10_2 = self.conv_op(deconv10_1, [3, 3, 64, 64], stride=1, name='10_2')
        conv10_3 = self.conv_op(conv10_2, [3, 3, 64, 64], stride=1, name='10_3')  # (?, 512, 512, 64)

        conv11 = self.conv_op(conv10_3, [3, 3, 64, 2], stride=1, name='end')

        prediction = self.prediction_result(conv11)
        return prediction

    def prediction_result(self, conv_result):
        # label = tf.cast(label, tf.int32)
        min_val = tf.constant(value=1.0e-10)
        conv_result = tf.reshape(conv_result, (-1, 2))  # 2 represent the class is 2
        conv_result = conv_result + min_val
        softmax = tf.nn.softmax(conv_result)  # (batch_size, height, width, channels)

        return softmax

    def cal_loss(self, prediction, labels):
        class_weight = np.array([25, 75], dtype='float32')
        min_val = tf.constant(value=1.0e-10)
        with tf.name_scope('loss'):
            labels = tf.reshape(tf.one_hot(labels, depth=2), (-1, 2))

            cross_entropy = -tf.reduce_sum(tf.multiply((labels * tf.log(prediction + min_val)), class_weight), axis=1)  # [1]
            # cross_entropy = -tf.reduce_sum(tf.multiply(labels, tf.log(prediction + min_val)), axis=1)

            cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')
            loss = cross_entropy_mean    #+ tf.add_n(tf.get_collection(('losses')))
            #tf.add_to_collection('losses', cross_entropy_mean)
            #loss = tf.add_n(tf.get_collection('losses'), name='total_losses')
        return loss






    def train(self, train_filename, model_path):
        impro = improcess()
        img_batch, label_batch = impro.read_batch(train_filename, self.batch_size)

        isTrain = tf.constant(True, dtype=tf.bool)

        prediction = self.inference(img_batch, isTrain)


        label = tf.reshape(tf.one_hot(label_batch, depth=2), (-1, 2))
        acc_val = tf.equal(tf.arg_max(prediction, 1), tf.arg_max(label, 1))

        
        #labels = tf.reshape(label_batch, (-1, 1))
        #acc_val = tf.equal(tf.arg_max(prediction, 1), tf.cast(labels, dtype=tf.int64), name='acc')
        
        accuracy = tf.reduce_mean(tf.cast(acc_val, dtype=tf.float32), name='acc')

        losses = self.cal_loss(prediction, label_batch)

        global_step = tf.Variable(0, trainable=False)
        variable_averages = tf.train.ExponentialMovingAverage(self.moving_average_decay, global_step)
        variables_averages_op = variable_averages.apply(tf.trainable_variables())

        learning_rate = tf.train.exponential_decay(self.learning_rate, global_step,
                                                   72 / self.batch_size,
                                                   self.learning_rate_decay)

        train_step = tf.train.AdamOptimizer(learning_rate).minimize(losses, global_step=global_step)
        # train_step = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(loss, global_step=global_step)

        with tf.control_dependencies([train_step, variables_averages_op]):
            train_op = tf.no_op(name='train')

        saver = tf.train.Saver()





        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            tf.local_variables_initializer().run()
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess=sess, coord=coord)

            num = 72 / self.batch_size

            for i in range(self.num_epochs):
                print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'
                print time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))
                print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'
                print 'Epoch %s/%s ' % (i, self.num_epochs)
                for j in range(num):
                    _, setp, acc, loss = sess.run([train_op, global_step, accuracy, losses])
                    if j == 3:
                        print '12/72   >..................................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 6:
                        print '24/72   --->..............................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 9:
                        print '36/72   ------>...........................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 12:
                        print '48/72   --------->........................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 15:
                        print '60/72   ------------>.....................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 18:
                        print '72/72   --------------->..................losses: %s    accuracy: %s' % (loss, acc)

            saver.save(sess, model_path)

            coord.request_stop()
            coord.join(threads)


    def prediction(self, pre_filein, model_file, pre_result_path):
        impro = improcess()
        img_batch = impro.read_batch_nolabel(pre_filein, self.batch_size)
        isTrain = tf.constant(True, dtype=tf.bool)

        prediction = self.inference(img_batch, isTrain, False)
        pre_val = tf.cast(tf.arg_max(prediction, 1), dtype=tf.int32)

        variable_average = tf.train.ExponentialMovingAverage(self.moving_average_decay)
        variables_to_restore = variable_average.variables_to_restore()

        saver = tf.train.Saver(variables_to_restore)
        out_arr = []
        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            tf.local_variables_initializer().run()
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess=sess, coord=coord)

            saver.restore(sess, model_file)
            nums = 1564 / self.batch_size
            for i in range(nums):
                pre_res = sess.run(pre_val)
                tmp_val = np.reshape(pre_res, (1, 200704))
                out_arr.append(tmp_val)

            coord.request_stop()
            coord.join(threads)
        out_arr = np.array(out_arr, dtype='int32')
        out_string = out_arr.tostring()

        tf.gfile.FastGFile(pre_result_path, 'wb').write(out_string)


if __name__ == '__main__':
    #train15_file = '/media/zb/ml/train_1572.tfrecords'
    train15_file = 'oss://remotecom/train15_new/train_file/train_1572.tfrecords'
    model15 = 'oss://remotecom/train15_new/model/model15.ckpt'

    test15_file = 'oss://remotecom/test_file15/test15.tfrecords'
    pre_result_path = 'oss://remotecom/train15_classweight001/pre_tif/precision001_noclass_weight.txt'




    net = SegNet(100, 4, 0.001, 0.99, 0.99)
    net.train(train15_file, model15)
    #net.prediction(test15_file, model15, pre_result_path)




