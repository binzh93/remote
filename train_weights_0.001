# -*- coding: utf8 -*-
import tensorflow as tf
import numpy as np
import time


class improcess():
    def __init__(self):
        self.file1 = '/home/zb/zzz/tuu/2015_all_fang.tif'
        self.file2 = '/home/zb/tmp/sp_new/sp_tiff/'
        self.file3 = '/home/zb/tmp/1/quickbird2015.tif'
        self.file4 = '/home/zb/tmp/sp_new/labeltiff/'

    def read_bacth_multifile(self, filein_path, bacth_size):
        reader = tf.TFRecordReader()
        files = tf.train.match_filenames_once(filein_path)

        filename_queue = tf.train.string_input_producer(files)
        _, queue_batch = reader.read_up_to(filename_queue, bacth_size)
        features = tf.parse_example(queue_batch, features={
            'image_raw': tf.FixedLenFeature([], tf.string),
        })

        imgs = tf.decode_raw(features['image_raw'], tf.float32)

        images_bacth = tf.reshape(imgs, (bacth_size, 224, 224, 8))

        return files, images_bacth

    def read_batch(self, filename, batch_size):
        # filename= '/home/zb/split_hhh/train15.tfrecords'
        file_queue = tf.train.string_input_producer([filename])
        reader = tf.TFRecordReader()
        _, queue_batch = reader.read_up_to(file_queue, batch_size)
        feature = tf.parse_example(queue_batch, features={
            'img_raw': tf.FixedLenFeature([], tf.string),
            'label': tf.FixedLenFeature([], tf.string)
        })
        imgs = tf.decode_raw(feature['img_raw'], tf.float32)
        labels = tf.decode_raw(feature['label'], tf.int32)

        img_batch = tf.reshape(imgs, (batch_size, 224, 224, 4))
        label_batch = tf.reshape(labels, (batch_size, 224, 224))

        return img_batch, label_batch

    def read_batch_nolabel(self, filename, batch_size):
        # filename= '/home/zb/split_hhh/train15.tfrecords'
        file_queue = tf.train.string_input_producer([filename])
        reader = tf.TFRecordReader()
        _, queue_batch = reader.read_up_to(file_queue, batch_size)
        feature = tf.parse_example(queue_batch, features={
            'img_raw': tf.FixedLenFeature([], tf.string),
        })
        imgs = tf.decode_raw(feature['img_raw'], tf.float32)

        img_batch = tf.reshape(imgs, (batch_size, 224, 224, 4))

        return img_batch


class SegNet():
    def __init__(self, num_epochs, batch_size, learning_rate, learning_rate_decay, moving_average_decay):
        self.num_epochs = num_epochs
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.learning_rate_decay = learning_rate_decay
        self.moving_average_decay = moving_average_decay

    # batch normalization
    def batch_normalization(self, input, isTraining, name):
        return tf.cond(isTraining,
                       lambda: tf.contrib.layers.batch_norm(input, is_training=isTraining, scope=name + '_bn'),
                       lambda: tf.contrib.layers.batch_norm(input, is_training=isTraining, scope=name + '_bn',
                                                            reuse=True))  # reuse=True

    def conv_op(self, input, kernel_shape, stride, isTraining, activation=True, name=None):
        depth = kernel_shape[3]
        with tf.variable_scope('conv' + name) as scope:

            kernel = tf.get_variable('conv-kernel', shape=kernel_shape,
                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())  # attention
            '''
            kernel = tf.get_variable('conv-kernel', shape=kernel_shape,
                                     initializer=tf.truncated_normal_initializer(stddev=0.1))  # attention
            '''

            biases = tf.get_variable('conv-biases', shape=[depth],
                                     initializer=tf.constant_initializer(0.0))
            conv = tf.nn.conv2d(input, kernel, strides=[1, stride, stride, 1], padding='SAME', name=scope.name)
            layer = tf.nn.bias_add(conv, biases)

        if activation is True:
            relu_val = tf.nn.relu(self.batch_normalization(layer, isTraining, scope.name))
        else:
            relu_val = self.batch_normalization(layer, isTraining, scope.name)
        return relu_val

    def deconv_op(self, input, kernel_shape, out_shape, stride, isTraining, activation=True, name=None):
        # attention kernel_shape's [2] [3] is changed, cause it's deconvolution
        depth = kernel_shape[2]
        with tf.variable_scope('deconv' + name) as scope:
            kernel = tf.get_variable('deconv-kernel', shape=kernel_shape,
                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())  # attention
            '''
            kernel = tf.get_variable('deconv-kernel', shape=kernel_shape,
                                     initializer=tf.truncated_normal_initializer(stddev=0.1))  # attention
            '''

            biases = tf.get_variable('deconv-biases', shape=[depth],
                                     initializer=tf.constant_initializer(0.0))

            deconv = tf.nn.conv2d_transpose(input, kernel, out_shape, strides=[1, stride, stride, 1],
                                            padding='SAME',
                                            name=scope.name)
            layer = tf.nn.bias_add(deconv, biases)
        if activation is True:
            relu_val = tf.nn.relu(self.batch_normalization(layer, isTraining, scope.name))
        else:
            relu_val = self.batch_normalization(layer, isTraining, scope.name)
        return relu_val

    def max_pool_with_argmax_op(self, input, stride, name):
        # tf.nn.max_pool_with_argmax, only GPU-supported, tf.nn.max_pool_with_argmax_and_mask seem to high version support
        return tf.nn.max_pool_with_argmax(input, ksize=[1, 2, 2, 1], strides=[1, stride, stride, 1], padding='SAME',
                                          name=name)

    def unpool(self, net, mask, stride, name):
        assert mask is not None
        with tf.name_scope(name):
            ksize = [1, stride, stride, 1]
            input_shape = net.get_shape().as_list()
            #  calculation new shape
            output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])
            # calculation indices for batch, height, width and feature maps
            one_like_mask = tf.ones_like(mask)
            batch_range = tf.reshape(tf.range(output_shape[0], dtype=tf.int64), shape=[input_shape[0], 1, 1, 1])
            b = one_like_mask * batch_range
            y = mask // (output_shape[2] * output_shape[3])
            x = mask % (output_shape[2] * output_shape[3]) // output_shape[3]
            feature_range = tf.range(output_shape[3], dtype=tf.int64)
            f = one_like_mask * feature_range
            # transpose indices & reshape update values to one dimension
            updates_size = tf.size(net)
            indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [4, updates_size]))
            values = tf.reshape(net, [updates_size])
            ret = tf.scatter_nd(indices, values, output_shape)
            return ret

    def inference(self, images, isTraining, isTraining2):
        # Local Response Normalization(局部响应归一化), 这里参数位经验值，论文中推荐的参数
        # 试一下，后期使用全局归一化的方法
        img_lrn = tf.nn.lrn(images, depth_radius=5, bias=1.0, alpha=0.0001, beta=0.75, name='img_lrn')

        # encode
        conv1_1 = self.conv_op(img_lrn, [3, 3, img_lrn.get_shape().as_list()[3], 64], stride=1, isTraining=isTraining,
                               name='1_1')  # 224*224*4  -> 224*224*64
        pool1, arg1 = self.max_pool_with_argmax_op(conv1_1, stride=2, name='pool1')  # 112*112*64

        conv2_1 = self.conv_op(pool1, [3, 3, 64, 128], stride=1, isTraining=isTraining, name='2_1')  # 112*112*128
        pool2, arg2 = self.max_pool_with_argmax_op(conv2_1, stride=2, name='pool2')  # 56*56*128

        conv3_1 = self.conv_op(pool2, [3, 3, 128, 256], stride=1, isTraining=isTraining, name='3_1')  # 56*56*256
        pool3, arg3 = self.max_pool_with_argmax_op(conv3_1, stride=2, name='pool3')  # 28*28*256

        if isTraining2 is True:
            pool3 = tf.nn.dropout(pool3, keep_prob=0.9)
        else:
            pool3 = tf.nn.dropout(pool3, keep_prob=1)

        conv4_1 = self.conv_op(pool3, [3, 3, 256, 512], stride=1, isTraining=isTraining, name='4_1')  # 28*28*512
        pool4, arg4 = self.max_pool_with_argmax_op(conv4_1, stride=2, name='pool4')  # 14*14*512

        conv5_1 = self.conv_op(pool4, [3, 3, 512, 512], stride=1, isTraining=isTraining, name='5_1')  # 14*14*512
        if isTraining2 is True:
            conv5_1 = tf.nn.dropout(conv5_1, keep_prob=0.9)
        else:
            conv5_1 = tf.nn.dropout(conv5_1, keep_prob=1)

        # decode
        unsampling1 = self.unpool(conv5_1, arg4, stride=2, name='unsampling1')  # 28*28*512
        deconv1_1 = self.deconv_op(unsampling1, [3, 3, 256, 512], [self.batch_size, 28, 28, 256], stride=1,
                                   isTraining=isTraining, name='1_1')  # 28*28*256

        unsampling2 = self.unpool(deconv1_1, arg3, stride=2, name='unsampling2')  # 56*56*256
        deconv2_1 = self.deconv_op(unsampling2, [3, 3, 128, 256], [self.batch_size, 56, 56, 128], stride=1,
                                   isTraining=isTraining, name='2_1')  # 56*56*256

        unsampling3 = self.unpool(deconv2_1, arg2, stride=2, name='unsampling3')  # 128*128*256
        deconv3_1 = self.deconv_op(unsampling3, [3, 3, 64, 128], [self.batch_size, 112, 112, 64], stride=1,
                                   isTraining=isTraining, name='3_1')  # 112*112*128
        if isTraining2 is True:
            deconv3_1 = tf.nn.dropout(deconv3_1, keep_prob=0.9)
        else:
            deconv3_1 = tf.nn.dropout(deconv3_1, keep_prob=1)

        unsampling4 = self.unpool(deconv3_1, arg1, stride=2, name='unsampling4')  # 224*224*64
        deconv4_1 = self.deconv_op(unsampling4, [3, 3, 64, 64], [self.batch_size, 224, 224, 64], stride=1,
                                   isTraining=isTraining, name='4_1')  # 112*112*64

        conv_res = self.conv_op(deconv4_1, [3, 3, 64, 2], stride=1, isTraining=isTraining, activation=False, name='end')

        prediction = self.prediction_result(conv_res)

        # loss = self.cal_loss(conv_res, labels)
        return prediction

    def prediction_result(self, conv_result):
        # label = tf.cast(label, tf.int32)
        min_val = tf.constant(value=1.0e-10)
        conv_result = tf.reshape(conv_result, (-1, 2))  # 2 represent the class is 2
        conv_result = conv_result + min_val
        softmax = tf.nn.softmax(conv_result)  # (batch_size, height, width, channels)

        return softmax

    def cal_loss(self, prediction, labels):
        class_weight = np.array([25, 75], dtype='float32')
        min_val = tf.constant(value=1.0e-10)
        with tf.name_scope('loss'):
            labels = tf.reshape(tf.one_hot(labels, depth=2), (-1, 2))

            cross_entropy = -tf.reduce_sum(tf.multiply((labels * tf.log(prediction + min_val)), class_weight), axis=1)  # [1]
            # cross_entropy = -tf.reduce_sum(tf.multiply(labels, tf.log(prediction + min_val)), axis=1)

            cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')
            tf.add_to_collection('losses', cross_entropy_mean)
            loss = tf.add_n(tf.get_collection('losses'), name='total_losses')
        return loss

    def train(self, train_filename, model_path):
        impro = improcess()
        img_batch, label_batch = impro.read_batch(train_filename, self.batch_size)
        isTrain = tf.constant(True, dtype=tf.bool)

        prediction = self.inference(img_batch, isTrain, True)

        label = tf.reshape(tf.one_hot(label_batch, depth=2), (-1, 2))
        acc_val = tf.equal(tf.arg_max(prediction, 1), tf.arg_max(label, 1))

        '''
        labels = tf.reshape(label_batch, (-1, 1))
        acc_val = tf.equal(tf.arg_max(prediction, 1), tf.cast(labels, dtype=tf.int64), name='acc')
        '''
        accuracy = tf.reduce_mean(tf.cast(acc_val, dtype=tf.float32), name='acc')

        losses = self.cal_loss(prediction, label_batch)

        global_step = tf.Variable(0, trainable=False)
        variable_averages = tf.train.ExponentialMovingAverage(self.moving_average_decay, global_step)
        variables_averages_op = variable_averages.apply(tf.trainable_variables())

        learning_rate = tf.train.exponential_decay(self.learning_rate, global_step,
                                                   1056 / self.batch_size,
                                                   self.learning_rate_decay)

        train_step = tf.train.AdamOptimizer(learning_rate).minimize(losses, global_step=global_step)
        # train_step = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(loss, global_step=global_step)

        with tf.control_dependencies([train_step, variables_averages_op]):
            train_op = tf.no_op(name='train')

        saver = tf.train.Saver()

        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            tf.local_variables_initializer().run()
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess=sess, coord=coord)

            num = 1056 / self.batch_size

            for i in range(self.num_epochs):
                print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'
                print time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))
                print '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'
                print 'Epoch %s/%s ' % (i, self.num_epochs)
                for j in range(num):
                    _, setp, acc, loss = sess.run([train_op, global_step, accuracy, losses])
                    if j == 12:
                        print '12/132   >..................................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 24:
                        print '24/132   --->...............................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 36:
                        print '36/132   ------>............................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 48:
                        print '48/132   --------->.........................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 60:
                        print '60/132   ------------>......................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 72:
                        print '72/132   --------------->...................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 84:
                        print '84/132   ------------------>................losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 96:
                        print '96/132   --------------------->.............losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 108:
                        print '108/132   ------------------------>.........losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 120:
                        print '120/132   --------------------------->......losses: %s    accuracy: %s' % (loss, acc)
                    elif j == 132:
                        print '132/132   ------------------------------>...losses: %s    accuracy: %s' % (loss, acc)

            saver.save(sess, model_path)

            coord.request_stop()
            coord.join(threads)

    def prediction(self, pre_filein, model_file, pre_result_path):
        impro = improcess()
        img_batch = impro.read_batch_nolabel(pre_filein, self.batch_size)
        isTrain = tf.constant(True, dtype=tf.bool)

        prediction = self.inference(img_batch, isTrain, False)
        pre_val = tf.cast(tf.arg_max(prediction, 1), dtype=tf.int32)

        variable_average = tf.train.ExponentialMovingAverage(self.moving_average_decay)
        variables_to_restore = variable_average.variables_to_restore()

        saver = tf.train.Saver(variables_to_restore)
        out_arr = []
        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            tf.local_variables_initializer().run()
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(sess=sess, coord=coord)

            saver.restore(sess, model_file)
            nums = 1564 / self.batch_size
            for i in range(nums):
                pre_res = sess.run(pre_val)
                tmp_val = np.reshape(pre_res, (1, 200704))
                out_arr.append(tmp_val)

            coord.request_stop()
            coord.join(threads)
        out_arr = np.array(out_arr, dtype='int32')
        out_string = out_arr.tostring()

        tf.gfile.FastGFile(pre_result_path, 'wb').write(out_string)


if __name__ == '__main__':
    train15_file = 'oss://remotecom/train15/train_file/train15.tfrecords'
    model15 = 'oss://remotecom/train15_classweight001/model/model15.ckpt'
    test15_file = 'oss://remotecom/test_file15/test15.tfrecords'
    pre_result_path = 'oss://remotecom/train15_classweight001/pre_tif/precision001_noclass_weight.txt'
    net = SegNet(150, 8, 0.001, 0.99, 0.99)
    net.train(train15_file, model15)
    #net.prediction(test15_file, model15, pre_result_path)

